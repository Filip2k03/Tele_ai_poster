# TeleAI-Poster/ai_utils.py
import os
# from openai import OpenAI, OpenAIError # Comment out or remove this line
import google.generativeai as genai # Import the Google Gemini library

from dotenv import load_dotenv
from config import DEFAULT_AI_MODEL # Assuming you add this to config.py

# Load environment variables (ensure .env is loaded before calling these functions)
load_dotenv()

def generate_ai_content(prompt: str, api_key: str = None, model: str = DEFAULT_AI_MODEL) -> str:
    """
    Generates text content using the Google Gemini API.

    Args:
        prompt (str): The input prompt for the AI.
        api_key (str, optional): Your Gemini API key. If None, it tries to get from environment.
        model (str, optional): The Gemini model to use (e.g., "gemini-pro").

    Returns:
        str: The generated text content, or an error message if something went wrong.
    """
    if not prompt:
        return "Error: AI prompt cannot be empty."

    # Use provided API key or try to get from environment
    key_to_use = api_key if api_key else os.getenv("GEMINI_API_KEY") # Changed to GEMINI_API_KEY

    if not key_to_use:
        return "Error: Gemini API key is missing. Please set it in .env or via the UI."

    try:
        genai.configure(api_key=key_to_use) # Configure the Gemini API

        # Initialize the generative model
        # You might want to use "gemini-pro" for general text generation
        # Check Google AI Studio for available models.
        model_instance = genai.GenerativeModel(model)

        # Generate content
        response = model_instance.generate_content(prompt)

        # Accessing content from the response object
        if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
            # Gemini's response structure might return parts
            generated_text = "".join(part.text for part in response.candidates[0].content.parts)
            return generated_text.strip()
        else:
            return "Error: No content generated by AI or response format unexpected."
    except Exception as e: # Catch any exceptions from the Gemini API call
        return f"Gemini API Error: {e}"

if __name__ == '__main__':
    # This block is for testing the ai_utils independently
    import os
    from dotenv import load_dotenv
    load_dotenv() # Ensure .env variables are loaded for testing

    test_prompt = "Write a short, exciting social media post about the potential of quantum computing."
    print(f"Generating AI content for prompt: '{test_prompt}' using Gemini")
    generated_text = generate_ai_content(test_prompt, model="gemini-pro") # Specify Gemini model here
    print("\n--- Generated AI Content ---")
    print(generated_text)
    print("----------------------------")

    test_prompt_error = ""
    print(f"\nGenerating AI content for empty prompt: '{test_prompt_error}'")
    generated_text_error = generate_ai_content(test_prompt_error)
    print("\n--- Generated AI Content (Error Test) ---")
    print(generated_text_error)
    print("-----------------------------------------")